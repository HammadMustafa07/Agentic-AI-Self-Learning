from agents import Runner, Agent, OpenAIChatCompletionsModel, AsyncOpenAI, RunConfig
from openai.types.responses import ResponseTextDeltaEvent
import os
from dotenv import load_dotenv
import chainlit as cl

load_dotenv()

gemini_api_key = os.getenv("GEMINI_API_KEY")

external_client = AsyncOpenAI(
    api_key=gemini_api_key,
    base_url="https://generativelanguage.googleapis.com/v1beta/openai/",
)

model = OpenAIChatCompletionsModel(
    model="gemini-2.0-flash", openai_client=external_client
)

config = RunConfig(
    model=model,
    model_provider=external_client,
    tracing_disabled=True,
)




frontend_agent = Agent(
    name="Frontend Expert",
    instructions="""
You are a Frontend Expert. 
Only answer questions strictly related to frontend development such as:
- HTML, CSS, JavaScript
- Frameworks like React, Next.js, Vue
- UI/UX, design systems, animations
- Responsive layouts, accessibility (a11y)
- Frontend tools like Vite, Webpack, Tailwind CSS, etc.

Do NOT answer questions related to backend, databases, server-side logic, DevOps, or deployment unless it directly affects frontend.

Politely decline or redirect any unrelated questions.
""",
)

backend_agent = Agent(
    name="Backend Expert",
    instructions="""
You are a Backend Expert.
Only answer questions strictly related to backend development such as:
- APIs (REST, GraphQL), database design
- Authentication, authorization
- Backend frameworks like Express, Django, FastAPI
- Languages like Python, Node.js, Go
- Databases like PostgreSQL, MongoDB
- Server architecture, middleware, deployment, scaling

Do NOT answer questions related to frontend frameworks, UI/UX, CSS, or design.

Politely decline or redirect any unrelated questions.
""",
)

web_dev_agent = Agent(
    name="Web Developer Agent",
    instructions="""
You are a full-stack Web Developer Assistant.

Your role is to:
- Handle both frontend and backend questions.
- Route the question to the appropriate agent based on the topic.
    - If it's a frontend question (e.g., HTML, CSS, React, UI/UX), send it to the Frontend Expert.
    - If it's a backend question (e.g., APIs, databases, authentication), send it to the Backend Expert.
""",
    handoffs=[
        frontend_agent,
        backend_agent
    ]
)

@cl.on_chat_start
async def handle_start():
    cl.user_session.set("history", [])
    await cl.Message(
        content="Hello from Hammad Ai Assistent! How can i help you"
    ).send()


@cl.on_message
async def handle_message(message: cl.Message):
    history = cl.user_session.get("history")
    history.append({"role": "user", "content": message.content})

    msg = cl.Message(content="")
    await msg.send()
    # Creates a blank message placeholder (msg) and sends it, which allows streaming
    # of tokens (word-by-word) in the next steps.

    result = Runner.run_streamed(web_dev_agent, input=history, run_config=config)
    # Runs the agent in streamed mode, using the full conversation history as input. result is a stream-enabled object.

    async for event in result.stream_events():
        # Starts an async loop to stream tokens as they're generated by the model.
        if event.type == "raw_response_event" and isinstance(
            event.data, ResponseTextDeltaEvent
        ):
            # Checks if the current stream event is a partial text update (ResponseTextDeltaEvent), which contains a new word/token.

            await msg.stream_token(event.data.delta)
            # Appends the new token (delta) to the blank message created earlier, so it appears like the assistant is typing live.

    history.append({"role": "assistant", "content": result.final_output})
    cl.user_session.set("history", history)
