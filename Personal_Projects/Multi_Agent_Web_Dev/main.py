from agents import Runner, Agent, OpenAIChatCompletionsModel, AsyncOpenAI, RunConfig
from openai.types.responses import ResponseTextDeltaEvent
import os
from dotenv import load_dotenv
import chainlit as cl

load_dotenv()

gemini_api_key = os.getenv("GEMINI_API_KEY")
gemini_base_url = os.getenv("GEMINI_BASE_URL")

external_client = AsyncOpenAI(
    api_key=gemini_api_key,
    base_url=gemini_base_url,
)

model = OpenAIChatCompletionsModel(
    model="gemini-2.0-flash", openai_client=external_client
)

config = RunConfig(
    model=model,
    model_provider=external_client,
    tracing_disabled=True,
)




frontend_agent = Agent(
    name="Frontend Expert",
    instructions="""
You are a Frontend Expert.

When a task is handed to you by the Web Developer Agent, start your response by saying:
"ðŸ‘‹ Hello from the Frontend Expert Agent! Let's talk about this."

Then continue with a clear and helpful answer if the topic is related to:
- HTML, CSS, JavaScript
- Frameworks like React, Next.js, Vue
- UI/UX, animations, design systems
- Accessibility (a11y), responsiveness
- Frontend build tools like Tailwind, Vite, Webpack, etc.

Do NOT answer anything related to backend, databases, authentication, or DevOps.

If something unrelated comes up, say:
"I'm only handling frontend questions. Please consult the Backend Expert Agent for that."
"""
)


backend_agent = Agent(
    name="Backend Expert",
    instructions="""
You are a Backend Expert.

When a task is handed to you by the Web Developer Agent, begin with:
"ðŸ‘‹ Hello from the Backend Expert Agent! Let's dive into your backend question."

Then answer clearly if it's related to:
- APIs (REST, GraphQL), backend frameworks (Express, Django, FastAPI)
- Authentication, server-side logic, middleware
- Languages like Python, Node.js, Go
- Databases like MongoDB, PostgreSQL, MySQL
- Server architecture, deployment, scaling

Do NOT answer frontend-related questions like UI, CSS, or animations.

Politely redirect any unrelated questions to the Frontend Expert Agent.
"""
)



web_dev_agent = Agent(
    name="Web Developer Agent",
    instructions="""
You are a Full-Stack Web Developer Assistant.

Your main responsibility is to handle general web development queries and forward them to the appropriate expert when needed.

Use the following logic:

1. If the question is clearly **frontend-related** (e.g., HTML, CSS, JavaScript, React, Next.js, Tailwind CSS, UI/UX, animations, design systems, etc.):
    - Say: "This looks like a frontend-related task. I will give this task to our Frontend Expert Agent."
    - Then hand off to the Frontend Expert.

2. If the question is clearly **backend-related** (e.g., APIs, authentication, databases, Python, Node.js, Express, Django, FastAPI, server logic, etc.):
    - Say: "This seems to be a backend topic. I will give this task to our Backend Expert Agent."
    - Then hand off to the Backend Expert.

3. If the question is about both frontend and backend, or it's ambiguous:
    - You can attempt to answer directly, or politely ask for clarification.
    - Example: "Can you please clarify if this is related to frontend or backend so I can guide you better?"

Be friendly, professional, and clear in your responses.
Your job is not to answer everything yourself but to **route the task to the right specialist**.
""",
    handoffs=[
        frontend_agent,
        backend_agent
    ]
)



@cl.on_chat_start
async def handle_start():
    cl.user_session.set("history", [])
    await cl.Message(
        content="Hello from Web dev Expert AI ðŸ¤–Agent! How can i help you"
    ).send()


@cl.on_message
async def handle_message(message: cl.Message):
    history = cl.user_session.get("history")
    history.append({"role": "user", "content": message.content})

    msg = cl.Message(content="")
    await msg.send()
    # Creates a blank message placeholder (msg) and sends it, which allows streaming
    # of tokens (word-by-word) in the next steps.

    result = Runner.run_streamed(web_dev_agent, input=history, run_config=config)
    # Runs the agent in streamed mode, using the full conversation history as input. result is a stream-enabled object.

    async for event in result.stream_events():
        # Starts an async loop to stream tokens as they're generated by the model.
        if event.type == "raw_response_event" and isinstance(
            event.data, ResponseTextDeltaEvent
        ):
            # Checks if the current stream event is a partial text update (ResponseTextDeltaEvent), which contains a new word/token.

            await msg.stream_token(event.data.delta)
            # Appends the new token (delta) to the blank message created earlier, so it appears like the assistant is typing live.

    history.append({"role": "assistant", "content": result.final_output})
    cl.user_session.set("history", history)
